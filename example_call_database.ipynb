{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoPhOT is built to be used across any telescope and their instruments. Fits files *should* follow the fits standard naming convention, although we found thoughout developent that a database is needed to translate discrepancies in naming conventions from different telescopes/instrument.\n",
    "\n",
    "As such, AutoPhOT creates a *telescope.yml* file in the directory given in **wdir**. **wdir** house the necasscary files for automated quick photometry. To date the house the *telescope.yml* file and *catalog_queries* folder containing sequence star calibration tables\n",
    "\n",
    "This noteboook highlights the operation of the *teledata2yml* function in the call_datacheck packge in autophot. Although this fucntion is executed during the *run* fucntion from autophot.autophot it can be executed beforehand such to take the care needed to build a reliable telescope/instrument database.\n",
    "\n",
    "This script is used as more of a demonstartion (and the user should be aware of) rather than something the user needs to be code up themselves. This function is executed everytime AutoPhOT is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autophot\n",
    "\n",
    "# this is the function we will be checking out\n",
    "from autophot.packages.call_datacheck import checkteledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['syntax', 'flst', 'filepath'], varargs=None, varkw=None, defaults=(None,), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this example we will make two files from the same telescope, but from different instruments. The data will be a random image but we'll focusing on the header information.\n",
    "\n",
    "For this demonstration we will make files from the NTT at La Silla which has EFOSC in sloan r and later in sloan g and SOFI in K band.\n",
    "We will have EFOSC follow ideal header keycards whereas SOFI will follow a different paradigm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration we will create a folder on the users desktop and save the **fake_EFOSC2** and **fake_SOFI**. Although there is no need for the user to follow this notebook on their machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# Get user homepath\n",
    "homedir = os.path.expanduser(\"~\")\n",
    "\n",
    "# Get path of desktop\n",
    "desktopdir = os.path.join(homedir,'Desktop')\n",
    "\n",
    "# get path of new directory called fake fits\n",
    "wdir = os.path.join(desktopdir,'fake_fits')\n",
    "\n",
    "# create direcrory called fake_fits\n",
    "os.makedirs(wdir,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a basic fits file with a image and header. The image will be random noise and we will all some basic keywords. First EFOSC with some standard header keywords and then SOFI where we change some keys to something more unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from astropy.io import fits\n",
    "\n",
    "# Fake EFOSC file \n",
    "data = random.random((50,50))\n",
    "\n",
    "hdu = fits.PrimaryHDU(data)\n",
    "hdul = fits.HDUList([hdu])\n",
    "\n",
    "fake_efosc_path = os.path.join(wdir,'Fake_EFOSC2.fits')\n",
    "\n",
    "hdul.writeto(fake_efosc_path,overwrite = True)\n",
    "\n",
    "# update fake_efosc2.fits with usual header keywords\n",
    "with fits.open(fake_efosc_path,'update') as f:\n",
    "    for hdu in f:\n",
    "        hdu.header['TELESCOP'] = ('ESO-NTT','added for example')\n",
    "        hdu.header['INSTRUME'] = ('EFOSC2','added for example')\n",
    "        hdu.header['FILTER'] = ('r','added for example')\n",
    "        hdu.header['EXPTIME'] = (60.0,'added for example')\n",
    "        hdu.header['GAIN'] = (1.0,'added for example')\n",
    "        hdu.header['MJD-OBS'] = (58849.,'added for example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake SOFI file \n",
    "\n",
    "data = random.random((50,50))\n",
    "\n",
    "hdu = fits.PrimaryHDU(data)\n",
    "hdul = fits.HDUList([hdu])\n",
    "\n",
    "fake_sofi_path = os.path.join(wdir,'Fake_SOFI.fits')\n",
    "hdul.writeto(fake_sofi_path,overwrite = True)\n",
    "\n",
    "# update fake_sofi.fits with some unique header keywords\n",
    "with fits.open(os.path.join(wdir,'Fake_SOFI.fits'),'update') as f:\n",
    "    for hdu in f:\n",
    "        hdu.header['TELESCOP'] = ('ESO-NTT','added for example')\n",
    "        hdu.header['INSTRUME'] = ('S_O_F_I','added for example')\n",
    "        hdu.header['FIL_WHL3'] = ('K_short','added for example')\n",
    "        hdu.header['EXPTIME'] = (60.0,'added for example')\n",
    "        hdu.header['GAIN_E'] = (1.0,'added for example')\n",
    "        hdu.header['MJD-OBS'] = (58849.,'added for example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the checkteledata and build the telescope.yml file. checkteledata has 3 arguments:\n",
    "* syntax: list of imput commands, although syntax['wdir'] is all that is needed\n",
    "* flist: list of filepaths of fits files\n",
    "* filepath: if telescope.yml is already create under another name fill in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files: ['/Users/seanbrennan/Desktop/fake_fits/Fake_SOFI.fits', '/Users/seanbrennan/Desktop/fake_fits/Fake_EFOSC2.fits']\n"
     ]
    }
   ],
   "source": [
    "# create a list of filepaths  \n",
    "flist = [fake_sofi_path,fake_efosc_path]\n",
    "print('List of files:',flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function relies on the syntax dictionary so we can load in the default dictionary and update our working directory (**wdir**). We can load the default file from autophot and update our wirking directory (**wdir**) from earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input loaded in from: \n",
      "/Users/seanbrennan/Documents/autophot_development/autophot_conda/autophot/autophot/databases/default_input.yml\n"
     ]
    }
   ],
   "source": [
    "# Load default synatx dictionary\n",
    "from autophot.prep_input import load\n",
    "syntax = load()\n",
    "\n",
    "syntax['wdir'] = wdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Name of Instrument [default: S_O_F_I]: \n",
      "Shorthand name [default: S_O_F_I]: SOFI\n",
      "Scale units [type skip to ignore]: skip\n",
      "Header Name of Instrument [default: EFOSC2]: \n",
      "Shorthand name [default: EFOSC2]: EFOSC\n",
      "Scale units [type skip to ignore]: skip\n",
      "Similar gain keywords found: \n",
      "['GAIN_E']\n",
      "Instrument Gain key [type skip to ignore]:\n",
      "[Telescope: ESO-NTT :: Inst: S_O_F_I] GAIN_E\n",
      "Relevant filter keywords found:\n",
      "File: Fake_SOFI.fits\n",
      "*** [Key - Value] ***\n",
      "FIL_WHL3 - K_short\n",
      "Corrosponding FILTER Keyword\n",
      "[Telescope: ESO-NTT :: Inst: INSTRUME]: FIL_WHL3\n",
      "Corrosponding filter - K_short\n",
      "[Telescope: ESO-NTT :: Inst: S_O_F_I][default: no_filter]: K\n",
      "Similar gain keywords found: \n",
      "['GAIN']\n",
      "Instrument Gain key [type skip to ignore]:\n",
      "[Telescope: ESO-NTT :: Inst: EFOSC2] GAIN\n"
     ]
    }
   ],
   "source": [
    "syntax = checkteledata(syntax,flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the telescope.yaml file has been great we can look it by loading the nest dictionary using yaml.safe_load and printing it with yaml.dump to check file structure - of course if this file is set up incorrectly you can edit it simply with a text editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESO-NTT:\n",
      "  INSTRUME:\n",
      "    EFOSC2:\n",
      "      GAIN: GAIN\n",
      "      Name: EFOSC\n",
      "      filter_key_0: FILTER\n",
      "      r: r\n",
      "      scale_high: null\n",
      "      scale_low: null\n",
      "      scale_type: null\n",
      "    S_O_F_I:\n",
      "      GAIN: GAIN_E\n",
      "      K_short: K\n",
      "      Name: SOFI\n",
      "      filter_key_0: FILTER\n",
      "      filter_key_1: FIL_WHL3\n",
      "      scale_high: null\n",
      "      scale_low: null\n",
      "      scale_type: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# The code will look for the telescope.yml in the wdir key given in the syntax\n",
    "telescope_yaml_path = os.path.join(wdir,'telescope.yml')\n",
    "\n",
    "with open(telescope_yaml_path, 'r') as f:\n",
    "   yaml_data = yaml.safe_load(f)\n",
    "    \n",
    "print(yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that files have been checked, if we rerun the function it won't ask up for any new entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = checkteledata(syntax,flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a new file from EFOSC2 but change the *FILTER* keyword *FIL* and the value from *r* to *gp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flist with new file ['/Users/seanbrennan/Desktop/fake_fits/Fake_SOFI.fits', '/Users/seanbrennan/Desktop/fake_fits/Fake_EFOSC2.fits', '/Users/seanbrennan/Desktop/fake_fits/Fake_EFOSC2_g.fits']\n"
     ]
    }
   ],
   "source": [
    "# Fake EFOSC file \n",
    "data = random.random((50,50))\n",
    "\n",
    "hdu = fits.PrimaryHDU(data)\n",
    "hdul = fits.HDUList([hdu])\n",
    "\n",
    "fake_efosc_g_path = os.path.join(wdir,'Fake_EFOSC2_g.fits')\n",
    "\n",
    "hdul.writeto(fake_efosc_g_path,overwrite = True)\n",
    "\n",
    "# update fake_efosc2.fits with usual header keywords\n",
    "with fits.open(fake_efosc_g_path,'update') as f:\n",
    "    for hdu in f:\n",
    "        hdu.header['TELESCOP'] = ('ESO-NTT','added for example')\n",
    "        hdu.header['INSTRUME'] = ('EFOSC2','added for example')\n",
    "        hdu.header['FIL'] = ('gp','added for example')\n",
    "        hdu.header['EXPTIME'] = (60.0,'added for example')\n",
    "        hdu.header['GAIN'] = (1.0,'added for example')\n",
    "        hdu.header['MJD-OBS'] = (58849.,'added for example')\n",
    "        \n",
    "        \n",
    "        \n",
    "# add this to flist\n",
    "flist.append(fake_efosc_g_path)\n",
    "print('Flist with new file',flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant filter keywords found:\n",
      "File: Fake_EFOSC2_g.fits\n",
      "*** [Key - Value] ***\n",
      "FIL - gp\n",
      "Corrosponding FILTER Keyword\n",
      "[Telescope: ESO-NTT :: Inst: INSTRUME]: FIL\n",
      "Corrosponding filter - gp\n",
      "[Telescope: ESO-NTT :: Inst: EFOSC2][default: no_filter]: g\n"
     ]
    }
   ],
   "source": [
    "syntax = checkteledata(syntax,flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were asked to enter the key corrosponing keyword (as any previous keyword wasn't found), filter keywords are saved as *filter_key_[1...2...3... etc]*, we were also asked to clarify what the value corrosponder to (*gp*?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESO-NTT:\n",
      "  INSTRUME:\n",
      "    EFOSC2:\n",
      "      GAIN: GAIN\n",
      "      Name: EFOSC\n",
      "      filter_key_0: FILTER\n",
      "      filter_key_1: FIL\n",
      "      gp: g\n",
      "      r: r\n",
      "      scale_high: null\n",
      "      scale_low: null\n",
      "      scale_type: null\n",
      "    S_O_F_I:\n",
      "      GAIN: GAIN_E\n",
      "      K_short: K\n",
      "      Name: SOFI\n",
      "      filter_key_0: FILTER\n",
      "      filter_key_1: FIL_WHL3\n",
      "      scale_high: null\n",
      "      scale_low: null\n",
      "      scale_type: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(telescope_yaml_path, 'r') as f:\n",
    "   yaml_data = yaml.safe_load(f)\n",
    "    \n",
    "print(yaml.dump(yaml_data, allow_unicode=True, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again now that all values are in telescope.yml they are no longer asked for. The script will ignore multiple files with the same details. It won't ask for multiple definitions of the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = checkteledata(syntax,flist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
